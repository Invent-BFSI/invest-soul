<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Azure Real-time Avatar (WebRTC)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body { font-family: system-ui, sans-serif; margin: 0; padding: 16px; }
    #video { width: 100%; max-width: 960px; aspect-ratio: 16/9; background: #000; }
    #controls { margin-top: 12px; display: flex; gap: 8px; }
    input[type="text"] { flex: 1; padding: 8px; }
    button { padding: 8px 12px; }
    #log { font-size: 12px; white-space: pre-wrap; background: #f6f8fa; margin-top: 12px; padding: 8px; }
  </style>
</head>
<body>
  <h1>Azure Real-time Avatar</h1>

  <video id="video" autoplay playsinline muted></video>
  <audio id="audio" autoplay></audio>

  <div id="controls">
    <button id="start">Start Session</button>
  </div>

  <div id="speakRow" style="margin-top:8px; display:none;">
    <input id="text" placeholder="Type something for the avatar to say…" />
    <button id="speak">Speak</button>
    <button id="stop">Stop</button>
    <button id="close">Close Session</button>
  </div>

  <div id="log"></div>

  <!-- Load Speech SDK (official) -->
  <script src="https://aka.ms/csspeech/jsbrowserpackageraw"></script>

  <script>
    const $ = (id) => document.getElementById(id);
    const log = (...a) => { console.log(...a); $('log').textContent += a.join(' ') + '\n'; };

    let peer, avatarSynthesizer, region;

    async function getConfig() {
      const r = await fetch('/api/config');
      if (!r.ok) throw new Error('Failed to load config');
      const j = await r.json();
      region = j.region;
      return j;
    }

    async function getSpeechToken() {
      const r = await fetch('/api/speech/token');
      if (!r.ok) throw new Error('Failed to fetch speech token');
      return r.json(); // { token, region }
    }

    async function getRelay() {
      const r = await fetch('/api/avatar/relay-token');
      if (!r.ok) throw new Error('Failed to fetch relay token');
      return r.json(); // { urls:[...], username:'...', credential:'...', ttl:'...' }
    }

    async function startSession() {
      await getConfig();

      log('Fetching short-lived Speech token…');
      const { token } = await getSpeechToken();

      log('Fetching ICE relay details…');
      const relay = await getRelay();
      const iceServers = [{
        urls: relay.urls.filter(u => u.startsWith('turn:')),
        username: relay.username,
        credential: relay.credential
      }];

      // 1) Create WebRTC PeerConnection with ICE (TURN) servers
      peer = new RTCPeerConnection({ iceServers });
      peer.oniceconnectionstatechange = () => log('ICE state:', peer.iceConnectionState);

      // 2) Wire remote tracks to <video>/<audio>
      peer.ontrack = (event) => {
        if (event.track.kind === 'video') $('video').srcObject = event.streams[0];
        if (event.track.kind === 'audio') $('audio').srcObject = event.streams[0];
      };
      peer.addTransceiver('video', { direction: 'sendrecv' });
      peer.addTransceiver('audio', { direction: 'sendrecv' });

      // 3) Configure Speech + Avatar with token
      const SpeechSDK = window.SpeechSDK;
      const speechConfig = SpeechSDK.SpeechConfig.fromAuthorizationToken(token, region);
      speechConfig.speechSynthesisVoiceName = "en-US-JennyNeural";

      const avatarConfig = new SpeechSDK.AvatarConfig("lisa", "casual-sitting");
      avatarConfig.backgroundColor = "#00FF00FF";

      // 4) Start the avatar (negotiates WebRTC)
      log('Starting avatar…');
      avatarSynthesizer = new SpeechSDK.AvatarSynthesizer(speechConfig, avatarConfig);

      await avatarSynthesizer.startAvatarAsync(peer)
        .then(() => log('Avatar started. You should see idle video.'))
        .catch((err) => { throw new Error('Avatar failed to start: ' + err); });

      $('speakRow').style.display = 'flex';
      $('video').muted = false; // unmute after user gesture
    }

    async function speak() {
      const text = $('text').value.trim();
      if (!text) return;
      try {
        const result = await avatarSynthesizer.speakTextAsync(text);
        if (result.reason === window.SpeechSDK.ResultReason.SynthesizingAudioCompleted) {
          log('Synthesis complete.');
        } else {
          log('Synthesis did not complete. ResultId:', result.resultId);
        }
      } catch (e) {
        log('Speak error:', e.message);
      }
    }

    async function stopSpeaking() {
      try { await avatarSynthesizer.stopSpeakingAsync(); } catch {}
    }

    function closeSession() {
      try { avatarSynthesizer?.close(); } catch {}
      try { peer?.close(); } catch {}
      log('Session closed.');
      $('speakRow').style.display = 'none';
    }

    $('start').addEventListener('click', startSession);
    $('speak').addEventListener('click', speak);
    $('stop').addEventListener('click', stopSpeaking);
    $('close').addEventListener('click', closeSession);
  </script>
</body>
</html>
