<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Innoviya â€” invest-soul</title>
  <style>
    body { font-family: system-ui, Arial, sans-serif; margin: 20px; }
    #log { border:1px solid #ddd; padding:12px; height:260px; overflow:auto; background:#fafafa }
    #avatarVideo { width: 520px; height: 292px; background: #000; }
    .row { margin: 8px 0; }
  </style>
</head>
<body>
<h2>Innoviya â€” AI Investment Advisory</h2>

<div class="row">
  <input id="txtUser" style="width:70%" placeholder="Speak or type your message..." />
  <button id="btnSend">Send</button>
  <button id="btnSpeak">ğŸ™ï¸ STT once</button>
</div>

<div class="row">
  <video id="avatarVideo" autoplay playsinline muted></video>
  <div>
    <label>Voice:</label> <input id="voice" value="en-US-JennyNeural"/>
    <label>Avatar:</label> <input id="avatarChar" value="lisa"/>
  </div>
</div>

<div id="log"></div>

<!-- Speech SDK -->
https://aka.ms/csspeech/jsbrowserpackageraw</script>
<script>
const API_BASE = location.origin;
let sessionId = null, speechToken=null, speechRegion=null, synthesizer=null, pc=null;

function log(s, who="sys"){ const el=document.getElementById('log'); const p=document.createElement('div'); p.textContent=`[${who}] ${s}`; el.appendChild(p); el.scrollTop=el.scrollHeight; }

async function fetchSpeechToken(){
  const r=await fetch(`${API_BASE}/speech/token`); if(!r.ok) throw new Error("token failed"); return r.json();
}

async function ensureAvatar(){
  const {token,region}=await fetchSpeechToken(); speechToken=token; speechRegion=region;
  const speechConfig=SpeechSDK.SpeechConfig.fromAuthorizationToken(token,region);
  speechConfig.speechSynthesisVoiceName=document.getElementById('voice').value||'en-US-JennyNeural';
  const avatarConfig=new SpeechSDK.AvatarConfig(document.getElementById('avatarChar').value||'lisa','casual'); // AvatarSynthesizer usage [3](https://learn.microsoft.com/en-us/javascript/api/microsoft-cognitiveservices-speech-sdk/avatarsynthesizer?view=azure-node-latest)
  synthesizer=new SpeechSDK.AvatarSynthesizer(speechConfig, avatarConfig);
  pc=new RTCPeerConnection();
  document.getElementById('avatarVideo').onloadedmetadata = ()=>{};
  pc.ontrack=(e)=>{ document.getElementById('avatarVideo').srcObject=e.streams[0]; };
  await synthesizer.startAvatarAsync(pc); // starts WebRTC flow; SDK docs detail this call. [3](https://learn.microsoft.com/en-us/javascript/api/microsoft-cognitiveservices-speech-sdk/avatarsynthesizer?view=azure-node-latest)
}

async function sttOnce(){
  const tok = speechToken ? {token:speechToken,region:speechRegion} : await fetchSpeechToken();
  const speechConfig=SpeechSDK.SpeechConfig.fromAuthorizationToken(tok.token, tok.region);
  speechConfig.speechRecognitionLanguage="en-US";
  const audioConfig=SpeechSDK.AudioConfig.fromDefaultMicrophoneInput();
  const recognizer=new SpeechSDK.SpeechRecognizer(speechConfig, audioConfig); // recognizeOnce pattern [11](https://docs.azure.cn/en-us/ai-services/speech-service/how-to-recognize-speech)
  return new Promise((resolve,reject)=>{
    recognizer.recognizeOnceAsync(res=>{
      if(res.reason===SpeechSDK.ResultReason.RecognizedSpeech) resolve(res.text);
      else reject(res.errorDetails||'no speech');
      recognizer.close();
    });
  });
}

async function chatSend(text){
  const r=await fetch(`${API_BASE}/chat`,{
    method:'POST',
    headers:{'Content-Type':'application/json'},
    body:JSON.stringify({ sessionId, temperature:0.3, max_tokens:800, messages:[{role:'user', content:text}] })
  });
  if(!r.ok) throw new Error("chat failed");
  const data=await r.json(); sessionId=data.sessionId; return data.content;
}

async function handleUserText(text){
  log(text, "you"); let reply = await chatSend(text);

  // Tool trigger - fetch top stocks
  if(reply.trim().startsWith("#fetch-top-stocks:")){
    const sector = reply.split(":")[1].trim();
    const r = await fetch(`${API_BASE}/market/top-stocks?sector=${encodeURIComponent(sector)}`);
    const data = await r.json();
    reply = await chatSend(`Market data received: ${JSON.stringify({marketTopStocks: data.top5})}`);
  }

  log(reply, "ai");
  try{
    if(!synthesizer) await ensureAvatar();
    await synthesizer.speakTextAsync(reply); // speak via avatar (WebRTC) [12](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/text-to-speech-avatar/real-time-synthesis-avatar)
  }catch(e){ console.warn("avatar speak", e); }
}

document.getElementById('btnSpeak').addEventListener('click', async()=>{
  try{ const t=await sttOnce(); document.getElementById('txtUser').value=t; await handleUserText(t); }
  catch(e){ log("STT: "+e, "err"); }
});
document.getElementById('btnSend').addEventListener('click', async()=>{
  const t=document.getElementById('txtUser').value.trim(); if(t) await handleUserText(t);
});
</script>
</body>
</html>
